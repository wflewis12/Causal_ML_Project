{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, log_loss\n",
    "import sklearn\n",
    "import os\n",
    "from matplotlib.pyplot import hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED=42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_stata(\"maindata.dta\", convert_categoricals=False)\n",
    "laws_csv = pd.read_csv(\"When_Were_Laws.csv\")\n",
    "laws_csv = laws_csv[np.logical_not(np.isnan(laws_csv[\"FIPS\"]))]  # FIPS codes identify states\n",
    "laws_csv = laws_csv.drop(\"State_Name\", axis=1)  # Dropping as useless\n",
    "laws_csv = laws_csv.rename({'FIPS': 'stfips'}, axis=1) \n",
    "\n",
    "# Merging\n",
    "merged = pd.merge(laws_csv, x, on='stfips', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_merged = merged.copy()  # To allow for re-running \n",
    "\n",
    "basic_merged = basic_merged[basic_merged[\"a_age\"] <= 25]  # Can be changed later, but for now useful I think\n",
    "#age_subset = np.logical_and(np.greater_equal(basic_merged[\"a_age\"],18), np.greater_equal(19,basic_merged[\"a_age\"]))\n",
    "# 17 <= age <= 21 (maybe should be like 22)\n",
    "#basic_merged = basic_merged[age_subset]\n",
    "#print(basic_merged.shape)\n",
    "\n",
    "# Dropping states who were treated < 97 (i.e. they always had programs)\n",
    "# This is following Callaway + Sant'anna, as we cannot meaningfully \n",
    "# do any inference using those states. Although we can compare them later as a \n",
    "# robustness check, which may be interesting\n",
    "basic_merged = basic_merged[basic_merged[\"Year_Implemented\"].str.contains(\"always\")==False]  \n",
    "\n",
    "# I also drop the never states, as they may be substantively different from others, although this can be relaxed later.\n",
    "basic_merged = basic_merged.replace(\"never\", \"1000000\") \n",
    "basic_merged[\"Year_Implemented\"] = basic_merged[\"Year_Implemented\"].astype(int)  # converting to intbasic_merged = basic_merged[basic_merged[\"Year_Implemented\"].str.contains(\"never\")==False]  # Only want to look at one for now. \n",
    "\n",
    "# As we are treating >19 as the never-treated group, we set their year implemented as 1000000 >> 1999\n",
    "year_implemented_vector = basic_merged[\"Year_Implemented\"].copy()\n",
    "year_implemented_vector[basic_merged[\"under19\"] == 0] = 1000000\n",
    "basic_merged[\"group\"] = year_implemented_vector  # Equals the year you were first treated. If >=19 then treated at t = infty\n",
    "\n",
    "# Drop Arizona since they implemented late and later repealed policy\n",
    "basic_merged = basic_merged[basic_merged[\"stfips\"] != 5]\n",
    "\n",
    "# Generating list of confounders of interest, these are not necessarily optimal. \n",
    "list_of_confounders = [\"fownu18\", \"a_maritl\", \"female\" , \"povll\"]#, \"stfips\"]\n",
    "list_of_confounders += [\"anykids\", \"disability\", \"collgrad\", \"hsgrad\"] # coll + hs are extra for now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_g_model():\n",
    "  return RandomForestClassifier(random_state = 42, n_estimators=100, max_depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treatment_k_fold_fit_and_predict(make_model, X:pd.DataFrame, A:np.array, n_splits:int):\n",
    "    \"\"\"\n",
    "    Implements K fold cross-fitting for the model predicting the treatment A. \n",
    "    That is, \n",
    "    1. Split data into K folds\n",
    "    2. For each fold j, the model is fit on the other K-1 folds\n",
    "    3. The fitted model is used to make predictions for each data point in fold j\n",
    "    Returns an array containing the predictions  \n",
    "\n",
    "    Args:\n",
    "    model: function that returns sklearn model (which implements fit and predict_prob)\n",
    "    X: dataframe of variables to adjust for\n",
    "    A: array of treatments\n",
    "    n_splits: number of splits to use\n",
    "    \"\"\"\n",
    "    predictions = np.full_like(A, np.nan, dtype=float)\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_SEED)\n",
    "    \n",
    "    for train_index, test_index in kf.split(X, A):\n",
    "      X_train = X.loc[train_index]\n",
    "      A_train = A.loc[train_index]\n",
    "      g = make_model()\n",
    "      g.fit(X_train, A_train)\n",
    "\n",
    "      # get predictions for split\n",
    "      predictions[test_index] = g.predict_proba(X.loc[test_index])[:, 1]\n",
    "\n",
    "    assert np.isnan(predictions).sum() == 0\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#overlap and g scores are calculated as the probabiliy that the indiviual is treated (under 19) in treated year given\n",
    "#that you were either in that state in 1997 or never treated at all (over age of 19)\n",
    "def calculate_g(treated_year):\n",
    "    sub_merged = basic_merged.copy()\n",
    "    \n",
    "    #data of indiviuals \n",
    "    sub_merged = sub_merged[(sub_merged[\"group\"] == treated_year) | (sub_merged[\"group\"] == 1000000)]\n",
    "    \n",
    "    #Creating binary variablee\n",
    "    treatment_bin = {treated_year: 1, 1000000: 0}\n",
    "    sub_merged.group = [treatment_bin[item] for item in sub_merged.group]\n",
    "    sub_merged = sub_merged.reset_index()\n",
    "    \n",
    "    treatment = sub_merged[\"group\"]\n",
    "    confounders = sub_merged[list_of_confounders]\n",
    "    \n",
    "    #Predicting g for a given year\n",
    "    g = treatment_k_fold_fit_and_predict(make_g_model, X=confounders, A=treatment, n_splits=10)\n",
    "    \n",
    "    return g\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([9.87453270e+00, 4.14058788e-01, 2.20641962e-02, 1.10699765e-01,\n",
       "        1.15273588e+00, 3.79731445e-02, 5.01700048e-01, 6.57333123e-01,\n",
       "        1.31817000e-01, 4.35602156e-03]),\n",
       " array([0.        , 0.07747571, 0.15495143, 0.23242714, 0.30990285,\n",
       "        0.38737857, 0.46485428, 0.54232999, 0.61980571, 0.69728142,\n",
       "        0.77475713]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g1 = calculate_g(1997)\n",
    "#plotting the propensity scores to check overlap\n",
    "hist(g1, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7747571319209327"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the largest propensity score\n",
    "g1.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:670: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_folds = np.zeros(n_samples, dtype=np.int)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:442: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  fold_sizes = np.full(n_splits, n_samples // n_splits, dtype=np.int)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:442: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  fold_sizes = np.full(n_splits, n_samples // n_splits, dtype=np.int)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neighbors/base.py:908: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  self._y = np.empty(y.shape, dtype=np.int)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neighbors/base.py:908: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  self._y = np.empty(y.shape, dtype=np.int)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neighbors/base.py:908: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  self._y = np.empty(y.shape, dtype=np.int)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neighbors/base.py:908: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  self._y = np.empty(y.shape, dtype=np.int)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neighbors/base.py:908: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  self._y = np.empty(y.shape, dtype=np.int)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neighbors/base.py:908: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  self._y = np.empty(y.shape, dtype=np.int)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neighbors/base.py:908: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  self._y = np.empty(y.shape, dtype=np.int)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-e1523500858a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mg2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_g\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1998\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdensity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-9b17ca865181>\u001b[0m in \u001b[0;36mcalculate_g\u001b[0;34m(treated_year)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mconfounders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msub_merged\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist_of_confounders\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtreatment_k_fold_fit_and_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_g_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfounders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtreatment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-45fc9021df8f>\u001b[0m in \u001b[0;36mtreatment_k_fold_fit_and_predict\u001b[0;34m(make_model, X, A, n_splits)\u001b[0m\n\u001b[1;32m     21\u001b[0m       \u001b[0mA_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m       \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m       \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m       \u001b[0;31m# get predictions for split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/neighbors/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/neighbors/base.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    255\u001b[0m             self._tree = KDTree(X, self.leaf_size,\n\u001b[1;32m    256\u001b[0m                                 \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meffective_metric_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m                                 **self.effective_metric_params_)\n\u001b[0m\u001b[1;32m    258\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_method\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'brute'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "g2 = calculate_g(1998)\n",
    "hist(g2, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.932666170478082"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g2.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([8.52532751, 0.99057759, 0.04205426, 0.01490146, 0.01955002,\n",
       "        1.30316062, 0.1066562 , 0.35216095, 1.08624233, 0.15314179]),\n",
       " array([0.        , 0.07940432, 0.15880865, 0.23821297, 0.31761729,\n",
       "        0.39702162, 0.47642594, 0.55583026, 0.63523459, 0.71463891,\n",
       "        0.79404323]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g3 = calculate_g(1999)\n",
    "hist(g3, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7940432327273385"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g3.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to loop through and different models and calculate the MSE and accuracy score for each one\n",
    "def fit_g(treated_year, g_model):\n",
    "    sub_merged = basic_merged.copy()\n",
    "    sub_merged = sub_merged[(sub_merged[\"group\"] == treated_year) | (sub_merged[\"group\"] == 1000000)]\n",
    "    \n",
    "    treatment_bin = {treated_year: 1, 1000000: 0}\n",
    "    sub_merged.group = [treatment_bin[item] for item in sub_merged.group]\n",
    "    sub_merged = sub_merged.reset_index()\n",
    "    \n",
    "    treatment = sub_merged[\"group\"]\n",
    "    confounders = sub_merged[list_of_confounders]\n",
    "    \n",
    "    x_train, x_test, a_train, a_test = train_test_split(confounders, treatment, test_size=0.2)\n",
    "    g_model.fit(x_train, a_train)\n",
    "    a_pred = g_model.predict_proba(x_test)[:,1]\n",
    "    \n",
    "    #Calculating MSE and accuracy score\n",
    "    test_ce=log_loss(a_test, a_pred)\n",
    "    baseline_ce=log_loss(a_test, a_train.mean()*np.ones_like(a_test))\n",
    "    score = g_model.score(x_test,a_test)\n",
    "    \n",
    "    return test_ce, baseline_ce, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of models\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "Rf_depth_2 = RandomForestClassifier(random_state = 42, n_estimators=100, max_depth=2)\n",
    "Rf_depth_10 = RandomForestClassifier(random_state = 42, n_estimators=100, max_depth=10)\n",
    "KNN = KNeighborsClassifier()\n",
    "LogReg = linear_model.LogisticRegression(multi_class='ovr', solver='liblinear')\n",
    "XGBoost = sklearn.ensemble.GradientBoostingClassifier()\n",
    "\n",
    "models = [Rf_depth_2, Rf_depth_10, KNN, LogReg, XGBoost]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to find the fit of a g model for a given year\n",
    "def fit_year(treated_year, models):\n",
    "    fit_stat = pd.DataFrame()\n",
    "    model_lst = [\"Rf_depth2\", \"RF_depth10\", \"KNN\", \"LogReg\", \"XGBoost\"]\n",
    "    g_ce = []\n",
    "    score = []\n",
    "    baseline = []\n",
    "\n",
    "    for model in models:\n",
    "        x, y, z = fit_g(treated_year, model)\n",
    "        g_ce.append(x)\n",
    "        baseline.append(y)\n",
    "        score.append(z)\n",
    "\n",
    "    fit_stat[\"model\"] = model_lst\n",
    "    fit_stat[\"g_ce\"] = g_ce\n",
    "    fit_stat[\"baseline_ce\"] = baseline\n",
    "    fit_stat[\"accuracy_score\"] = score\n",
    "\n",
    "    return fit_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>g_ce</th>\n",
       "      <th>baseline_ce</th>\n",
       "      <th>accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Rf_depth2</td>\n",
       "      <td>0.283902</td>\n",
       "      <td>0.346638</td>\n",
       "      <td>0.889951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>RF_depth10</td>\n",
       "      <td>0.213491</td>\n",
       "      <td>0.350360</td>\n",
       "      <td>0.906568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>KNN</td>\n",
       "      <td>1.000770</td>\n",
       "      <td>0.351579</td>\n",
       "      <td>0.885347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>LogReg</td>\n",
       "      <td>0.229034</td>\n",
       "      <td>0.351236</td>\n",
       "      <td>0.899121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.216690</td>\n",
       "      <td>0.355592</td>\n",
       "      <td>0.904404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model      g_ce  baseline_ce  accuracy_score\n",
       "0   Rf_depth2  0.283902     0.346638        0.889951\n",
       "1  RF_depth10  0.213491     0.350360        0.906568\n",
       "2         KNN  1.000770     0.351579        0.885347\n",
       "3      LogReg  0.229034     0.351236        0.899121\n",
       "4     XGBoost  0.216690     0.355592        0.904404"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_year(1997, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>g_ce</th>\n",
       "      <th>baseline_ce</th>\n",
       "      <th>accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Rf_depth2</td>\n",
       "      <td>0.365156</td>\n",
       "      <td>0.448285</td>\n",
       "      <td>0.834745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>RF_depth10</td>\n",
       "      <td>0.260663</td>\n",
       "      <td>0.447528</td>\n",
       "      <td>0.882643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>KNN</td>\n",
       "      <td>1.270768</td>\n",
       "      <td>0.447023</td>\n",
       "      <td>0.872863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>LogReg</td>\n",
       "      <td>0.280128</td>\n",
       "      <td>0.449212</td>\n",
       "      <td>0.879832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.261032</td>\n",
       "      <td>0.447275</td>\n",
       "      <td>0.881556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model      g_ce  baseline_ce  accuracy_score\n",
       "0   Rf_depth2  0.365156     0.448285        0.834745\n",
       "1  RF_depth10  0.260663     0.447528        0.882643\n",
       "2         KNN  1.270768     0.447023        0.872863\n",
       "3      LogReg  0.280128     0.449212        0.879832\n",
       "4     XGBoost  0.261032     0.447275        0.881556"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_year(1999, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only testing fit for 1998\n",
    "sub_merged = basic_merged.copy()\n",
    "sub_merged = sub_merged[(sub_merged[\"group\"] == 1998) | (sub_merged[\"group\"] == 1000000)]\n",
    "    \n",
    "treatment_bin = {1998: 1, 1000000: 0}\n",
    "sub_merged.group = [treatment_bin[item] for item in sub_merged.group]\n",
    "sub_merged = sub_merged.reset_index()\n",
    "    \n",
    "treatment = sub_merged[\"group\"]\n",
    "confounders = sub_merged[list_of_confounders]\n",
    "    \n",
    "x_train, x_test, a_train, a_test = train_test_split(confounders, treatment, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_g2(g_model):\n",
    "    g_model.fit(x_train, a_train)\n",
    "    a_pred = g_model.predict_proba(x_test)[:,1]\n",
    "    \n",
    "    test_ce=log_loss(a_test, a_pred)\n",
    "    baseline_ce=log_loss(a_test, a_train.mean()*np.ones_like(a_test))\n",
    "    score = g_model.score(x_test,a_test)\n",
    "    \n",
    "    return test_ce, baseline_ce, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>g_ce</th>\n",
       "      <th>baseline_ce</th>\n",
       "      <th>accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Rf_depth2</td>\n",
       "      <td>0.499453</td>\n",
       "      <td>0.657917</td>\n",
       "      <td>0.858877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>RF_depth10</td>\n",
       "      <td>0.354816</td>\n",
       "      <td>0.657917</td>\n",
       "      <td>0.861143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>KNN</td>\n",
       "      <td>1.699834</td>\n",
       "      <td>0.657917</td>\n",
       "      <td>0.826930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>LogReg</td>\n",
       "      <td>0.383680</td>\n",
       "      <td>0.657917</td>\n",
       "      <td>0.856638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.354318</td>\n",
       "      <td>0.657917</td>\n",
       "      <td>0.860973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model      g_ce  baseline_ce  accuracy_score\n",
       "0   Rf_depth2  0.499453     0.657917        0.858877\n",
       "1  RF_depth10  0.354816     0.657917        0.861143\n",
       "2         KNN  1.699834     0.657917        0.826930\n",
       "3      LogReg  0.383680     0.657917        0.856638\n",
       "4     XGBoost  0.354318     0.657917        0.860973"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_stat = pd.DataFrame()\n",
    "model_lst = [\"Rf_depth2\", \"RF_depth10\", \"KNN\", \"LogReg\", \"XGBoost\"]\n",
    "g_ce = []\n",
    "score = []\n",
    "baseline = []\n",
    "\n",
    "for model in models:\n",
    "    x, y, z = fit_g2(model)\n",
    "    g_ce.append(x)\n",
    "    baseline.append(y)\n",
    "    score.append(z)\n",
    "\n",
    "fit_stat[\"model\"] = model_lst\n",
    "fit_stat[\"g_ce\"] = g_ce\n",
    "fit_stat[\"baseline_ce\"] = baseline\n",
    "fit_stat[\"accuracy_score\"] = score\n",
    "\n",
    "fit_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
