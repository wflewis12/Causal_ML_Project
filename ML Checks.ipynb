{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, log_loss\n",
    "import sklearn\n",
    "import os\n",
    "from matplotlib.pyplot import hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_stata(\"maindata.dta\", convert_categoricals=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "laws_csv = pd.read_csv(\"When_Were_Laws.csv\")\n",
    "laws_csv = laws_csv[np.logical_not(np.isnan(laws_csv[\"FIPS\"]))]  # FIPS codes identify states\n",
    "laws_csv = laws_csv.drop(\"State_Name\", axis=1)  # Dropping as useless\n",
    "laws_csv = laws_csv.rename({'FIPS': 'stfips'}, axis=1) \n",
    "\n",
    "# Merging\n",
    "merged = pd.merge(laws_csv, x, on='stfips', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_merged = merged.copy()  # To allow for re-running \n",
    "\n",
    "basic_merged = basic_merged[basic_merged[\"a_age\"] <= 25]  # Can be changed later, but for now useful I think\n",
    "\n",
    "# Dropping states who were treated < 97 (i.e. they always had programs)\n",
    "# This is following Callaway + Sant'anna, as we cannot meaningfully \n",
    "# do any inference using those states. Although we can compare them later as a \n",
    "# robustness check, which may be interesting\n",
    "basic_merged = basic_merged[basic_merged[\"Year_Implemented\"].str.contains(\"always\")==False]  \n",
    "\n",
    "# Making it so that \"never-treated\" states are treated at T = infinity\n",
    "basic_merged = basic_merged.replace(\"never\", \"1000000\") \n",
    "basic_merged[\"Year_Implemented\"] = basic_merged[\"Year_Implemented\"].astype(int)  # converting to int\n",
    "\n",
    "# Indicator for if the individual was treated (i.e. under 19 and in a state who added a law)\n",
    "basic_merged[\"treatment\"] = basic_merged[\"under19\"] # * basic_merged[\"year_indic\"]\n",
    "\n",
    "# Generating list of confounders of interest, these are not necessarily optimal. \n",
    "list_of_confounders = [\"year\", \"stfips\", \"fownu18\", \"faminctm1\", \"a_maritl\", \"female\" , \"fpovcut\", \"povll\"]\n",
    "list_of_confounders += [\"anykids\", \"disability\", \"noemp_insured\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML Checks for One Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_merged = basic_merged.copy()\n",
    "sub_merged = sub_merged[sub_merged[\"Year_Implemented\"] == 1997]\n",
    "sub_merged = sub_merged[sub_merged[\"year\"] == 1997]\n",
    "confounders_and_treat = sub_merged[[\"treatment\",\"year\", \"stfips\", \"fownu18\", \"faminctm1\", \"a_maritl\", \"female\" , \"fpovcut\", \"povll\", \"anykids\", \"disability\", \"noemp_insured\"]]\n",
    "y_var = sub_merged[\"pubonly\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(confounders_and_treat, y_var, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE of fit model 0.06748466257668712\n",
      "Model Score: 0.9325153374233128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error, log_loss\n",
    "Q1 = RandomForestClassifier()\n",
    "Q1.fit(x_train, y_train)\n",
    "y_pred = Q1.predict(x_test)\n",
    "\n",
    "test_mse=mean_squared_error(y_pred, y_test)\n",
    "print(f\"Test MSE of fit model {test_mse}\") \n",
    "\n",
    "score2 = Q1.score(x_test,y_test)\n",
    "print(\"Model Score: \" + str(score2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE of fit model 0.09406952965235174\n",
      "Model Score: 0.9059304703476483\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "Q2 = KNeighborsClassifier()\n",
    "Q2.fit(x_train, y_train)\n",
    "y_pred = Q2.predict(x_test)\n",
    "\n",
    "test_mse=mean_squared_error(y_pred, y_test)\n",
    "print(f\"Test MSE of fit model {test_mse}\") \n",
    "\n",
    "score2 = Q2.score(x_test,y_test)\n",
    "print(\"Model Score: \" + str(score2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE of fit model 0.07975460122699386\n",
      "Model Score: 0.9202453987730062\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "Q3 = linear_model.LogisticRegression(multi_class='ovr', solver='liblinear')\n",
    "Q3.fit(x_train, y_train)\n",
    "y_pred = Q3.predict(x_test)\n",
    "\n",
    "test_mse=mean_squared_error(y_pred, y_test)\n",
    "print(f\"Test MSE of fit model {test_mse}\")\n",
    "score2 = Q3.score(x_test,y_test)\n",
    "print(\"Model Score: \" + str(score2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE of fit model 0.07770961145194274\n",
      "Model Score: 0.9222903885480572\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "Q4 = MLPClassifier(solver='adam', hidden_layer_sizes=(15,), random_state=1, max_iter=500)\n",
    "Q4.fit(x_train, y_train)\n",
    "y_pred = Q4.predict(x_test)\n",
    "\n",
    "test_mse=mean_squared_error(y_pred, y_test)\n",
    "print(f\"Test MSE of fit model {test_mse}\")\n",
    "\n",
    "score2 = Q4.score(x_test,y_test)\n",
    "print(\"Model Score: \" + str(score2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE of fit model 0.05725971370143149\n",
      "Model Score: 0.9427402862985685\n"
     ]
    }
   ],
   "source": [
    "Q5 = sklearn.ensemble.GradientBoostingClassifier()\n",
    "Q5.fit(x_train, y_train)\n",
    "y_pred = Q5.predict(x_test)\n",
    "\n",
    "test_mse=mean_squared_error(y_pred, y_test)\n",
    "print(f\"Test MSE of fit model {test_mse}\")\n",
    "\n",
    "score2 = Q5.score(x_test,y_test)\n",
    "print(\"Model Score: \" + str(score2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML Checks For All Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "confounders_and_treat = basic_merged[[\"treatment\",\"year\", \"stfips\", \"fownu18\", \"faminctm1\", \"a_maritl\", \"female\" , \"fpovcut\", \"povll\", \"anykids\", \"disability\", \"noemp_insured\"]]\n",
    "y_var = basic_merged[\"pubonly\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(confounders_and_treat, y_var, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE of fit model 0.0937240365565284\n",
      "Model Score: 0.9062759634434716\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error, log_loss\n",
    "Q1 = RandomForestClassifier()\n",
    "Q1.fit(x_train, y_train)\n",
    "y_pred = Q1.predict(x_test)\n",
    "\n",
    "test_mse=mean_squared_error(y_pred, y_test)\n",
    "print(f\"Test MSE of fit model {test_mse}\") \n",
    "\n",
    "score2 = Q1.score(x_test,y_test)\n",
    "print(\"Model Score: \" + str(score2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE of fit model 0.11306746767218423\n",
      "Model Score: 0.8869325323278158\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "Q2 = KNeighborsClassifier()\n",
    "Q2.fit(x_train, y_train)\n",
    "y_pred = Q2.predict(x_test)\n",
    "\n",
    "test_mse=mean_squared_error(y_pred, y_test)\n",
    "print(f\"Test MSE of fit model {test_mse}\") \n",
    "\n",
    "score2 = Q2.score(x_test,y_test)\n",
    "print(\"Model Score: \" + str(score2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE of fit model 0.11387699452504207\n",
      "Model Score: 0.8861230054749579\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "Q3 = linear_model.LogisticRegression(multi_class='ovr', solver='liblinear')\n",
    "Q3.fit(x_train, y_train)\n",
    "y_pred = Q3.predict(x_test)\n",
    "\n",
    "test_mse=mean_squared_error(y_pred, y_test)\n",
    "print(f\"Test MSE of fit model {test_mse}\")\n",
    "score2 = Q3.score(x_test,y_test)\n",
    "print(\"Model Score: \" + str(score2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE of fit model 0.10450352570247758\n",
      "Model Score: 0.8954964742975224\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "Q4 = MLPClassifier(solver='adam', hidden_layer_sizes=(15,), random_state=1, max_iter=500)\n",
    "Q4.fit(x_train, y_train)\n",
    "y_pred = Q4.predict(x_test)\n",
    "\n",
    "test_mse=mean_squared_error(y_pred, y_test)\n",
    "print(f\"Test MSE of fit model {test_mse}\")\n",
    "\n",
    "score2 = Q4.score(x_test,y_test)\n",
    "print(\"Model Score: \" + str(score2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE of fit model 0.09519396689461239\n",
      "Model Score: 0.9048060331053877\n"
     ]
    }
   ],
   "source": [
    "Q5 = sklearn.ensemble.GradientBoostingClassifier()\n",
    "Q5.fit(x_train, y_train)\n",
    "y_pred = Q5.predict(x_test)\n",
    "\n",
    "test_mse=mean_squared_error(y_pred, y_test)\n",
    "print(f\"Test MSE of fit model {test_mse}\")\n",
    "\n",
    "score2 = Q5.score(x_test,y_test)\n",
    "print(\"Model Score: \" + str(score2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
